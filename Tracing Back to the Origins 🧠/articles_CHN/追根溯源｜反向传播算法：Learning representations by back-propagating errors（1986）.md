上一节Perceptron的文章提到，感知机的一个主要问题是仅有输入层和输出层，不能解决线性不可分问题。在1986年的一篇论文 *Learning representations by back-propagating errors* [1] 中，Rumelhart, Hinton 等人提出了一种称为反向传播的学习方法（现在已经耳熟能详了），旨在通过调整网络中连接的权重，最小化神经网络中神经元单元实际输出和期望输出之间的差异，从而使得网络可以自动学习和优化复杂任务中的内部特征表示。这篇论文不仅奠定了人们现在所熟悉的深度学习理论基础，也开启了神经网络在实际应用中的广泛探索。除此之外，文章末尾还提出了一些从当今的视角看来，非常有意思的观点，值得我们一探究竟。

**简介**

在设计能够自我组织的神经网络时，科学家们进行了许多尝试。他们的目标是找到一种有效的方法，使网络中的连接能够**学习和自我调整，自动找到适合完成特定任务的内部连接和状态**。如果输入和输出直接连接在一起，找到学习的方法相对比较简单，只需通过反复调整连接的强度，让输出越来越接近目标结果即可。然而，输出与输入直连的网络只能处理线性可分问题。举个例子，假如有一篮子苹果和西瓜，因为它们在大小和维度上都有明显的差异，所以我们可以用一条直线在大小-重量图上将苹果和西瓜分开。在这一类问题中，存在一条直线/一个超平面可以在一个二维或多维空间中完全地将不同类别的数据点分开。然而，现实中的许多数据特征不具备良好的区分能力，像影评的情感评论（正面还是负面？），股票市场预测（涨还是跌？），都无法用一条简单的线性边界划开。

为了解决这些线性不可分的问题，隐藏层 (hidden layer) 的概念被提出了。隐藏层的状态并不是直接给定的，必须通过**学习**来决定接触到什么刺激神经元才会激活，一层一层地处理下去，最后使网络正确输出结果。在感知机中，虽然关联层 (association area) 位于输入和输出之间，但它们的连接是固定的，不会进行学习。在这篇论文中，几位作者找到了一种简单强大的方法（也就是我们现在熟知的反向传播算法），能够自动调整隐藏单元的状态，构建出适合任务需求的内部表示。后面的内容会先讲解反向传播算法的核心，介绍几个作者提出的特殊例子，最后再讨论算法的改进点以及一些有趣的问题。

**反向传播**

这一部分会详细介绍反向传播的计算流程，权重的具体更新规则会在下一部分讲解。

考虑任意层状结构的网络，它们由输入单元，不限数量的隐藏层，与输出单元构成。每一层内的单元同时设置状态，从输入单元开始向上，直到输出单元的状态被确定。图一是论文中神经元连接与计算方式的简易演示：

![[Pasted image 20240806135047.png]]
图一：相邻层间神经元的加权连接，激活函数与输出。

神经元 $j$ 的总输入 $x_j$ 是连接到 $j$ 的单元 $y_i$ 的输出和这些连接的权重 $w_{ji}$ 的线性函数：
$$\begin{equation}x_j=\sum_i y_i w_{ji}\end{equation}$$
其中的 $i$ 和 $j$ 实际代表的是前后网络层中神经元的索引，这里简单地称作“神经元 $j$”，“神经元 $i$”。除此之外，还可以在神经元的总输入中提供一个固定的偏移量，我们将其称作**偏置** (bias)。加入偏置后的输入写作：$$x_j=b_j+\sum_i y_i w_{ji}$$神经元的实值输出 $y_j$ 是其总输入 $x_j$ 的非线性函数：$$\begin{equation}y_j=f(x_j)=\frac{1}{1+e^{-x_j}}\end{equation}$$Sigmoid 函数是一个十分常用的激活函数，它的所有输出值都在 $(0,1)$ 之间，并且导数形式非常简单 $\sigma^{'}(x)=\sigma (x)(1-\sigma(x))$。人工神经元的结构可以与生物神经元的结构作类比，如图二所示。
![[Pasted image 20240806220302.png]]
图二：生物神经元与人工神经元的类比——输入，求和，激活，输出。

我们的终极目标是，确保对于每个输入向量，网络生成的**输出向量与期望的输出向量相同或者足够近**。网络性能的总误差可以通过比较实际输出向量和期望输出向量来计算，定义总误差 $E$：$$\begin{equation}E=\frac{1}{2}\sum_c \sum_j (y_{j,c}-d_{j,c})^2\end{equation}$$其中，$c$ 是样本的索引，$j$ 是输出单元的索引，$y$ 是输出单元的实际状态，$d$ 是其期望状态。

对于给定的数据样本，在向前传播的过程中，误差相对于每个权重的偏导数需要通过两次传递来计算，每层单元的状态由下层单元接收到的输出决定。反向传播则更为复杂，权重导数将会从输出层传递到底层，基于 $\frac{\partial E}{\partial w}$ 与一定规则不断调整相应权重。图三描述了反向传播的计算流程。

![[Pasted image 20240807220440.png]]
图三：偏导数计算流程。

考虑一个特定样本 $c$，计算输出单元的 $\frac{\partial E}{\partial y_j}$：$$\begin{equation}\frac{\partial E}{\partial y_j}=y_j-d_j\end{equation}$$应用链式法则，得到 $\frac{\partial E}{\partial x_j}$：$$\frac{\partial E}{\partial x_j}=\frac{\partial E}{\partial y_j}\cdot \frac{d y_j}{d x_j}$$对公式(2)进行微分得到 $\frac{dy_j}{d x_j}$ 并代入得到：
$$\begin{equation}\frac{\partial E}{\partial x_j}=\frac{\partial E}{\partial y_j} \cdot y_j\cdot (1-y_j)\end{equation}$$这意味着我们知道输出单元的总输入 $x_j$ 是如何影响误差 $E$ 的。根据(1)，因为总输入只是较低单元状态和连接权重的线性函数，所以可以很容易地计算权重改变对于误差的影响。对于从单元 $i$ 到 $j$ 的权重 $w_{ji}$：$$\begin{equation}\frac{\partial E}{\partial w_{ji}}=\frac{\partial E}{\partial x_j}\cdot \frac{\partial x_j}{\partial w_{ji}}=\frac{\partial E}{\partial x_j}\cdot y_i\end{equation}$$至此，我们已经完成了一层的传递；为了得到网络中每一层的 $\frac{\partial E}{\partial w_{ji}}$，需要继续求解前一层的 $\frac{\partial E}{\partial y_j}$。对于单元 $i$ 的输出，$\frac{\partial E}{\partial y_j}$ 的贡献由 $i$ 对 $j$ 的影响产生：$$\frac{\partial E}{\partial y_i}=\frac{\partial E}{\partial x_j}\cdot \frac{\partial x_j}{\partial y_i}=\frac{\partial E}{\partial x_j}\cdot w_{ji}$$考虑从单元 $i$ 出发的所有连接：$$\begin{equation}\frac{\partial E}{\partial y_i}=\sum_j \frac{\partial E}{\partial x_j}\cdot w_{ji}\end{equation}$$等式(7)给出了如何在给定最后一层所有单元的 $\frac{\partial E}{\partial y}$ 时计算倒数第二层任何单元的 $\frac{\partial E}{\partial y}$。这样一来，可以重复整个过程，得出权重对于误差的导数，再使用 $\frac{\partial E}{\partial w}$ 更新梯度。

**使用梯度更新权重**

为了尽可能地缩小总误差，使输出与期望接近，一种常用的方法是通过**梯度下降** (gradient descent) 最小化 $E$。梯度下降就像下山的过程，为了达到山谷的最低点，求的使误差最小的权重设置，需要不断换股四周，寻找坡度最大的方向（计算梯度），迈出适当大小的步伐（学习率），一步一步地向下走，直到现在的权重是。梯度下降最简单的版本是将权重按与 $\frac{\partial E}{\partial w}$ 成比例的量进行更改：$$\begin{equation}\Delta w=-\eta \frac{\partial E}{\partial w}\end{equation}$$$\eta$ 就是学习率。这种方法的收敛速度不如利用二阶导数的方法快，但它更简单，并且可以通过并行硬件中的局部计算轻松实现。然而，使用这种方法却面临一个问题：当学习率过大时，权重可能会在接近局部最小值的过程中于最小值附近来回震荡，导致永远无法收敛，如图四所示。

![[Pasted image 20240807225551.png]]
图四：局部最小值周围的震荡现象。

同时，若学习率设置的过小，收敛速度会非常慢，一样不可行。文章提出了一种简单的加速方法——动量法，可以在不牺牲算法的简洁的情况下显著改进收敛速度：$$\begin{equation}\Delta w(t)=-\eta \frac{\partial E}{\partial w}(t)+\alpha \Delta w(t-1)\end{equation}$$其中，$t$ 对每次遍历整个输入-输出案例集的增量为1，$\alpha$ 是介于0和1之间的指数衰减因子，确定当前梯度和早期梯度对权重变化的相对贡献。动量法就像是在物理运动中添加了“惯性”。当一个物体在某个方向上运动时，惯性使得它在没有外力作用时继续沿着这个方向运动。类似地，在梯度下降中，该方法通过结合当前梯度与前一次梯度乘上一定系数来更新权重，从而加速在较平坦区域的收敛速度，使动量的累积帮助参数快速接近最优解。事实上，梯度下降只是找到局部最优问题中最基础的方法之一，近年来也不断地有更多优秀的算法出现。

最后一个要说明的点就是权重的起始值。如果神经网络在初始化时，所有神经元的权重相同，那么在训练的过程中，每个神经元将接收到相同的梯度，并做出相同的更新。这样一来，网络就无法学习到不同的特征，学习能力受到限制。为了打破这种**对称性**问题，权重的初始化是随机的。

下一个板块将介绍作者提出的几个有趣的任务。

**几个有趣的案例**

1. 镜像对称网络
![[Pasted image 20240808125525.png]]图五：一个学习到如何识别镜像对称的网络。

这个任务的核心目标是，对于一个长度为6的二进制向量，神经网络能够识别出形如 $[1,0,1,1,0,1]$ 这样的对称结构。网络由6个输入单元组成，两个隐藏单元，以及单个输出单元。模型训练运用了随机均匀分布在-0.3到0.3之间的初始权重，共进行了1425次遍历，每次遍历所有可能的 $2^6=64$ 个输入向量；学习率设定为 $\eta=0.1$，动量因子 $\alpha=0.9$。

下面对图五中网络学习到的内容做一些解读。对于每个隐藏单元，权重在大小上相等，符号相反。隐藏单元具有负偏置（-1.1）：当输入单元的净输入为0时，隐藏单元将处于关闭状态；输出单元具有正偏置（6.4）：当隐藏单元都关闭时，输出单元将被激活。因为中点两侧的权重比例为1:2:4，所以中点上方的每个模式向隐藏单元发送的激活总和是唯一的，只有对称模式才能在中点下方完全平衡这个总和。当输入向量对称时，因为对称的权重相互抵消，每个隐藏单元的净输入将为0。因此，隐藏单元将由于负偏置而关闭，输出单元由于其正偏置而被激活，检测到对称模式。

2. 家族树网络
![[Pasted image 20240808134839.png]]图六：（左）两个同构的家族树；（右）家族树网络的activity level。

家族树的信息可以用三元组 (person1, relationship, person2) 的形式表示，其中可能的关系包括父亲、母亲、兄弟、姐妹等。如果我们的网络可以通过给出的前两个元素来生成第三个元素，这就说明它成功学习了这些三元组。

训练数据集由0和1组成的二进制向量表示，每个人物和关系都用独热编码 (one-hot encoding) 表示。例如，“Colin”的独热编码向量可能是 $[1, 0, 0, …, 0]$（24位），而“has-aunt”关系的独热编码向量可能是 $[0, 0, 1, …, 0]$（12位）。输入向量由人物和关系的独热编码向量连接而成，形成一个长度为36 (24 + 12) 的二进制向量。家族树网络训练一共经历1500次遍历，前20次遍历使用 $\eta=0.005$ 和 $\alpha=0.5$，后续使用了 $\eta=0.01$ 和 $\alpha=0.9$。

图六右边两组中的白色方块显示了各单元的活动水平。第一组中有一个活跃单元代表Colin，第二组中有一个活跃单元代表关系“有一个姑姑”。两个输入组会分别由六个单元构成的隐藏层，第二层再全连接到中央层的12个单元，继而过渡到倒数第二层的6个单元。倒数第二层的活动会激活正确的输出单元，每个输出单元代表一个特定的人物 (person 2)。我们可以在右图上白方框内看到两个黑点，这意味着 (Colin)(has-aunt) 的输出有两个正确答案——Colin有两个姑姑。

3. 同步迭代网络与等效神经网络
![[Pasted image 20240808205203.png]]
图七：一个递归神经网络与等效的神经网络。

图七展示了一个递归神经网络；在这一类网络中，每一次权重更新对应于层状网络中的一层。在创建与递归网络等效的层状结构时，我们会面临两个问题：
- 在层状网络中，中间层的输出在反向传播过程中是必需的。因此，在迭代网络中，需要**存储每个单元的输出状态历史**，以便在反向传播时使用。
- 为了**确保层状网络和迭代网络的等效性**，需要确保不同层之间的对应权重具有相同的值。这可以通过对每组对应权重的 $\frac{\partial E}{\partial w}$ 值进行平均，并根据这一平均梯度按比例改变每组对应权重中的每个权重来实现：$$\Delta w=\frac{\eta}{n}\sum_{i=1}^n \frac{\partial E}{\partial w_i}$$经过这两个修改，上文描述的学习过程可以直接应用于迭代网络。

**结语**

模型与案例部分至此已经介绍完毕；正是这个简单的算法，使神经网络能够学习复杂的非线性模式，并且推动许多现代深度学习技术的发展。文章在末尾还提出一个观点：作者们认为，**前向传播-损失计算-反向传播**的学习过程在生物学上并不完全合理，但是在实践中表现出色。因此，我们有必要寻找更符合生物学原理的算法来模拟学习。

然而，从当今的眼光来看，Resnet，Transformer，以及许多网络结构与优化算法与生物/神经科学的关系并不大。另外一方面，也有许多人质问，以'Money is all you need'著称的深度学习是否能带领我们走向真正的AGI？现在的人工智能是否走错道路了？再回到Back-propagation论文末尾的观点，实现智能是否需要神经科学的依据？生物学、乃至哲学与计算机的跨学科，是否会成为未来攻破这些问题的关键？

对于这些大问题，笔者认为在研究的过程中，我们完全可以将 artificial intelligence 与 intelligence 分开考量。“人工智能”这个名字使我们陷入了各种科技伦理问题的漩涡，但或许它也有一定误导性。**智能**牵扯到的领域不止有推理，计算，决策等行为表征，还与复杂的情感与意识问题联系在一起；神经网络这个四字使我们联想到智能，但我们也同样可以用“一个基于误差计算与参数优化的输入-隐藏-输出模型”来描述它。一方面，如何规范地应用人工智能，比起“我们有没有走错路”，或许是一个更近在咫尺，亟需解决的问题。何况，人类需不需要复刻出来的智能意识体，也是有带商榷的。

然而，笔者也仍然认为，人工智能是一个绝佳的出发点，来让我们继续构建学科之间的复杂联系，从量化的，科学的角度来对智能/意识问题抽丝剥茧，哪怕只能拨开一小片乌云。

后面几期专栏会介绍1979年的工作 Neocognitron，卷积神经网络与计算机视觉的开山之作；在介绍完基础模型之后，会进入人工智能/神经科学/哲学的跨学科讨论版块。

最后的最后，创作不易，读到这里，还是求个点赞收藏啦！（*＾3＾*）

**引用**

[1] Rumelhart, D. E., Hinton, G. E., & Williams, R. J. (1986). Learning representations by back-propagating errors. _Nature_, _323_(6088), 533–536. https://doi.org/10.1038/323533a0



